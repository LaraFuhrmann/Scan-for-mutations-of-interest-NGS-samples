"""
Input to the workflow is the current date.
Output is a file with the mutations of interest and heatmap

1. Get sampels of interests --> here Augustes code is probably useful
2. use bcf file generated by V-pipe
3. Translate bcf file to vcf
4. Annoated vcf file with amino acids
5. filter and merged togehter annoated files to csv
6. Collect interesting coverage information for posiitons of interests
7. Generate heatmap
"""
import yaml
from datetime import date, datetime, timedelta
import pandas as pd

def load_config(path):
    with open(path, 'r') as stream:
        config = yaml.safe_load(stream)
    return config

config = load_config("config/config.yaml")

# rule definitions
rule all:
    input:
        "results/mutations.filtered.csv",
        "results/coverage_all.csv",
        #"results/heatmap.pdf",

## 1. Get sampels of interests --> here Augustes code is probably useful
## # TODO: use here probably Augustes code to generate list of samples of interest
## https://github.com/gordonkoehn/UsefulGnom/blob/main/config/base_coverage.yaml
## https://github.com/cbg-ethz/virus-private/issues/29

fpath_timeline = config['fpath_timeline']
startdatetime =  datetime.now()
enddatetime = startdatetime - timedelta(weeks=5)

## This function is copied from https://github.com/gordonkoehn/UsefulGnom/blob/main/src/usefulgnom/serialize/coverage.py#L8
## and was created by Auguste and Gordon

def extract_sample_ID(
    timeline_file_dir: str,
    startdate: datetime = datetime.strptime("2024-01-01", "%Y-%m-%d"),
    enddate: datetime = datetime.strptime("2024-07-03", "%Y-%m-%d"),
    location: str = "Zürich (ZH)",
) -> pd.DataFrame:
    """
    Extract the sample ID of the samples from selected time period,
    location, and protocol. extract the date of the samples.

    Seelects sampled from 2022-07 to 2023-03 and location Zürich by default.

    Args:
        timeline_file_dir (str): Path to the timeline file.
        startdate (datetime): Start date of the time period.
        enddate (datetime): End date of the time period.
        location (str): Location of the samples.
        protocol (str): Sequencing protocol used.
                         eg. for filtering condition to take
                             only Artic v4.1 protocol: "v41"

    Returns:
        pd.DataFrame: DataFrame containing the sample ID and date.
    """
    timeline_file = pd.read_csv(
        timeline_file_dir,
        sep="\t",
        usecols=["sample", "proto", "date", "location"],
        encoding="utf-8",
    )
    # convert the "date" column to datetime type:
    timeline_file["date"] = pd.to_datetime(timeline_file["date"])

    selected_rows = timeline_file[
        # TODO: remove subsample selection line below
        # (according to samples.wastewateronly.ready.tsv)
        (timeline_file["date"] > startdate.strftime("%Y-%m-%d"))
        & (timeline_file["date"] < enddate.strftime("%Y-%m-%d"))
        & (timeline_file["location"].isin([location]))
    ]

    samples_ID = selected_rows[["sample", "date"]]
    return samples_ID



# get samples_IDs from the specified location, time and sequencing protocol

sample_IDs = extract_sample_ID(
        fpath_timeline, startdatetime, enddatetime, "Zürich (ZH)"
    )

print(sample_IDs)
all_samples = ["E2_19_2024_10_01/20241018_AAG55WNM5"]


## 2. use bcf file generated by V-pipe
## 3. Translate bcf file to vcf
rule bcf2vcf:
    input:
        fname_bcf=config['base_path_vpipe_output']+"{sample}/references/consensus.bcftools.bcf.gz",
    output:
        fname_vcf=config['base_path_vpipe_output']+"{sample}/references/consensus.bcftools.vcf",
    conda:
        "envs/annotate_vcf.yaml"
    shell:
        """
        bcftools view -O v -o {output.fname_vcf} {input.fname_bcf}
        bcftools norm -m -both -o {output.fname_vcf} {output.fname_vcf}
        """


## 4. Annoated vcf file with amino acids
rule annotate_vcf:
    input:
        fname_snvs_vcf=config['base_path_vpipe_output']+"{sample}/references/consensus.bcftools.vcf",
        fname_genbank_file=config['fpath_genome_annotation'],
    output:
        fname_snvs_vcf=config['base_path_vpipe_output']+"{sample}/references/consensus.bcftools.annotated.vcf",
    conda:
        "envs/annotate_vcf.yaml"
    script:
        "./scripts/annotate_vcf.py"



## 5. filter and merged togehter annoated files to csv
rule merge_mutations_of_interest:
    input:
        fnames_snv_csv=[config['base_path_vpipe_output']+f"{sample}/references/consensus.bcftools.annotated.vcf"
        for sample in all_samples],
    output:
        fname_result_csv="results/mutations.csv",
        fname_result_csv_filtered="results/mutations.filtered.csv",
    params:
        all_samples=all_samples,
        fname_mutation_list=config['fpath_mutation_of_interests'],
    conda:
        "envs/annotate_vcf.yaml"
    script:
        "./scripts/merge_mutations.py"


## 6. Collect interesting coverage information for posiitons of interests
## 5. filter and merged togehter annoated files to csv
rule merge_coverage:
    input:
        fnames=[
            config['base_path_vpipe_output']+f"{sample}/alignments/coverage.tsv.gz" # 1-based
            for sample in all_samples
        ],
    params:
        samples=all_samples,
    output:
        fname_result_csv="results/coverage_all.csv",
    params:
        params=all_samples,
    run:
        import pandas as pd
        tmp = []
        for sample, fname in zip(params.samples, input.fnames):
            df_tmp =  pd.read_csv(fname, sep="\t")
            df_tmp['sample'] = sample
            tmp.append(df_tmp)
        pd.concat(tmp).to_csv(output.fname_result_csv)


## 7. Generate heatmap
